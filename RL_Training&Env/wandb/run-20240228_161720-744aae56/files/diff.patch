diff --git a/RL_Training&Env/run_baseline_v2.py b/RL_Training&Env/run_baseline_v2.py
index 4a62f07..4599aae 100644
--- a/RL_Training&Env/run_baseline_v2.py
+++ b/RL_Training&Env/run_baseline_v2.py
@@ -1,6 +1,7 @@
 from os.path import exists
 from pathlib import Path
 import datetime
+import uuid
 from PkRed_env.red_gym_env_v2 import RedGymEnv
 from stream_agent_wrapper import StreamWrapper
 from stable_baselines3 import PPO, A2C, DQN
@@ -52,17 +53,19 @@ def make_model(algorithm):
 
 if __name__ == "__main__":
     current_datetime_str = datetime.datetime.now().strftime("%m%d%H%M%S")
-    use_wandb_logging = False
-    algorithm = "DQN"
+    use_wandb_logging = True
+    algorithm = "PPO"
     batch_size = 128
     n_epochs = 3
     gamma = 0.998
     learn_steps = 32
-    sess_path = Path(f'Sessions/{algorithm}_Session_{current_datetime_str}_env2_1')
+    sess_id = str(uuid.uuid4())[:8]
+    sess_path = Path(f'Sessions/{algorithm}_Session_{current_datetime_str}_{sess_id}_env2_1')
     # sess_path = Path(f'Sessions/PPO_Session_0226082405_env2_2')
     print(sess_path)
     num_cpu = 11 #! cannot go any higher than 12 <- also crashes after 3-4 hours
     ep_length = 2048 * num_cpu 
+    total_timesteps = (ep_length)*num_cpu*10000
 
     env_config = {
                 'headless': True, 'save_final_state': False, 'early_stop': False,
@@ -79,10 +82,25 @@ if __name__ == "__main__":
     checkpoint_callback = CheckpointCallback(save_freq=ep_length//2, save_path=sess_path,
                                      name_prefix="poke")
     
-    callbacks = [checkpoint_callback, TensorboardCallback(sess_path)]
+    callbacks = [checkpoint_callback, TensorboardCallback()]
+
+    # log to wandb
+    if use_wandb_logging:
+        import wandb
+        from wandb.integration.sb3 import WandbCallback
+        run = wandb.init(
+            project="pokemon-red-train",
+            id=sess_id,
+            config=env_config,
+            sync_tensorboard=True,  
+            monitor_gym=True,  
+            save_code=True,
+        )
+        callbacks.append(WandbCallback())
 
     # put a checkpoint here you want to start from
     file_name = "Sessions/PPO_Session_0226082405_env2_1/poke_36799488_steps"
+
     train_steps_batch = ep_length
     if exists(file_name + ".zip"):
         print("\nloading checkpoint")
@@ -93,9 +111,15 @@ if __name__ == "__main__":
         model.rollout_buffer.n_envs = num_cpu
         model.rollout_buffer.reset()
     else:
+        print("\nloading new model!")
         model = make_model(algorithm)
 
     print(model.policy)
 
-    model.learn(total_timesteps=(ep_length)*num_cpu*10000, callback=CallbackList(callbacks), tb_log_name="poke_ppo")
+    print(f"trianing for {total_timesteps} steps... \n {total_timesteps / num_cpu} steps per agent!.")
+
+    model.learn(total_timesteps=total_timesteps, callback=CallbackList(callbacks), tb_log_name="poke_ppo")
+
 
+    if use_wandb_logging:
+        run.finish()
\ No newline at end of file
