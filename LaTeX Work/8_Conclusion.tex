\section{Conclusion}


(one of the examples issues that arose during training)

Due to the environment's large search space, it was feasibly impossible to expect the agent to complete the game nor complete the first gym via random actions, which is why a sparse reward is needed to guide the agent by feeding it small amounts of reward to converge towards the optimal policy. The sparse reward for the Pokemon Red environment was implemented using a mix of on-screen information and RAM readings, which is reward shaping that would only work for Pokemon Red. Therefore, it would be impossible to use the same trained policy for other games without retraining the agent on a more suitable environment. This is one issue with reinforcement learning, as the field of RL is not mature enough to be able to create policies that can be transferred to other environments without retraining.

The issue with RL is that having mixed positive and negative rewards makes learning very difficult, as the agent interprets the cumulative reward instead of the aspects  which build up to the cumulative reward. Therefore, mixed positive and negative reward may lead to a cumulative reward of zero which would by neither encouragment or discouragement to the agent. 

Another issue with RL is that unlike humans, RL does not have a motivator to problem solving. Within any given RL environment, the environment itself is a problem the agent is attempting to solve through the use of the reward function. However, within the environment the agent has smaller subproblems that build up to the overall problem. The agent does not have a motivator to solve these subproblems, instead, if a negative reward is assigned, it learns to avoid the set of actions which leads to these problems. It could be argued that if the subproblems build up the overall problem, then the agent would eventually solve them given enough reward shaping. However, the agent would not have the critical thinking to solve the subproblems and instead learn to blindly maximize reward without understanding the environment. In addition, the more human intervention and hand holding required to solve the environment the more rigid and less generalizable the policy becomes.
