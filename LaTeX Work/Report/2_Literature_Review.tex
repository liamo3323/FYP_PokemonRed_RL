\section{Literature Review}

List of things to cover:

- justify research: -> what is pkmn and RPG games \& why did I chose pkmn red

- up-to-date with relevant literature: -> the algorithms I plan on using and why?

\subsection{Introduction to Pokemon Red}

Pokémon Red is a role-playing game where the player's goal is to defeatt the eight Gym Leaders and the Elite Four. The game is played from a top-down perspective and the player controls the actions of the main character. The player has to navigate the main character around the overworld, interact with non-player characters, and battle with wild Pokémon and other trainers. The game's combat is a turn-based battle system, where the player selects moves for their Pokémon to perform in battle. The game has a large number of items, moves, and abilities that the player can use to their advantage in battle. Therefore, large amount of variance makes each playthrough of the game unique while keeping goals consistent for each play through.

\subsection{Why Pokemon Red?}

RL has only been applied to every Atari game, where it surpassed the human benchmark for every game \cite{brockman2016openai}. However, these games lack long term randomness, where present actions influencing future states and future decisions. Every pokemon game takes at least 30 hours to complete, where every tiny decision made at every minute has an influence on the future. An example of this would be the decision of which pokemon to catch and train or which pokemon you start you journey with. The agent cannot defeat the game if it is able to navigate the map confidently but avoid battling, and on the other hand, the agent cannot complete the game if it chooses to only battle and not explore the map.
 
In addition, other similar projects exist that apply reinforcement learning to pokemon to find the optimal battling strategy by Kalose et al \cite{kalose2018optimal}. 
Their work focuses on the pokemon battling combat aspect of the game. However, I believe that it does not have a large enough search space to justify application of RL techniques because applying the same set of actions will always lead to very similar states, therefore making it possible for a rule based algorithm to perform pokemon battling optimally. 
Another similar work by Flaherty, Jimenez and Abbasi \cite{flaherty2021playing} applies reinforcement learning algorithms A2C and DQN to play Pokémon Red. However, this piece of work explores the time it takes to traini the different agents using RAM observations versus image observations. I aim to extend their research by applying and comparing more algorithms and various RL techniques to find the optimal path to complete the game.

\subsection{Why choose RL?}

Within the field of machine learning, there are multiple different forms of learning that can be applied to the environment of pokemon red. However, due to the depth of the action space of the environment, reinforcement learning is the best form of machine learning to explore how to find the optimal path to completing the game. 

The biggest drawback when using supervised or unsupervised learning is the dataset. The dataset would need someone playing the game for countless hours completing the game or reaching a checkpoint in the game before starting another episode of playing the game to provide a more varied dataset. Not only is this method increcible slow, as humans can only play and operate at a certain speed, but the dataset would also never experience actions that are unnatural for a human to perform, as the dataset is bound to the actions a human would take with the human's preconception of how to play the game. This leads onto the other issue, where the dataset of human playing the game is bound by human constaints. Humans are naturally lazy and have short attention spans, which means when the person providing the training data knows one way to solve a puzzle, they are unlikely to experiment other methods in solving the puzzle. Therefore, the agents trained on the human provided data are bound and limited by the performance of the human and will never find a more optimal path. 

RL is the solution to finding the set of action to complete the game as it allows the agent to 'play' the game itself and explore the environment in a sped-up space to find the optimal path without the need of a human to show it how to play, while knowing what the goal is. 

\subsection*{Why choose Reinforcement Learning for this problem?}

\subsection{RL Algorithms and Methods}